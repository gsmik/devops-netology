# Домашнее задание к занятию 6. «Troubleshooting»## Задача 1Перед выполнением задания ознакомьтесь с документацией по [администрированию MongoDB](https://docs.mongodb.com/manual/administration/).Пользователь (разработчик) написал в канал поддержки, что у него уже 3 минуты происходит CRUD-операция в MongoDB и её нужно прервать. Вы как инженер поддержки решили произвести эту операцию:- напишите список операций, которые вы будете производить для остановки запроса пользователя;- предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB.*Ответ** напишите список операций, которые вы будете производить для остановки запроса пользователя;  * Сперва необходимо найти долгие запросы    ```shell    db.currentOp({ "active" : true, "secs_running" : {"$gt" : 180} })    ```  db.currentOp() - возвращает документ который содержит информацию о выполняемых операциях в инстансе mongodb\    { "active" : true } - Активные операции\    { "secs_running" : {"$gt" : 180} } -операции выполняемые в течении заданного времени в секундах (в нашем случае 180 сек = 3 мин)  Будем считать, что запрос мы нашли  * Теперь выполним то, о чем просят    ```shell    db.killOp(opid)    ```    killOp() - завершает операцию по ID операции\    opid - идентификационный номер операции    * предложите вариант решения проблемы с долгими (зависающими) запросами в MongoDB    * Включить профайлинг если не включен. `db.setProfilingLevel(1,{ slowms: x }`), где `x` - количесьво милисекунд    * Ограничить время выполнения запрос(ов)а `maxTimeMS()`## Задача 2Перед выполнением задания познакомьтесь с документацией по [Redis latency troobleshooting](https://redis.io/topics/latency).Вы запустили инстанс Redis для использования совместно с сервисом, который использует механизм TTL. Причём отношение количества записанных key-value-значений к количеству истёкших значений есть величина постоянная иувеличивается пропорционально количеству реплик сервиса. При масштабировании сервиса до N реплик вы увидели, что:- сначала происходит рост отношения записанных значений к истекшим,- Redis блокирует операции записи.Как вы думаете, в чём может быть проблема?*Ответ** Изначально, проблема похожа на нехватку памяти. Т.е первое что приходит в голову - увеличить объем ОЗУ.Теперь еще раз идем в мануал находим следующий пункт **"Latency generated by expires"** и читаем о том, как redis удаляет ключи 2 способами.  * Lazy Way   > One lazy way expires a key when it is requested by a command, but it is found to be already expired.  * Active Way   > One active way expires a few keys every 100 milliseconds.  Ну и получается, что при росте устаревших записей, которые не успевают удалиться, Redis переходит к блокировке операций записи.\  Возвращаясь к документации, приходит осознание того, что каждые 100мс redis удалчет 20 записей (параметр **ACTIVE_EXPIRE_CYCLE_LOOKUPS_PER_LOOP** имеет значение 20)  Если количество записей превысит 25%, то сервис заблокирует операции записи, пока не снизит этот показатель до 25%.   ## Задача 3Вы подняли базу данных MySQL для использования в гис-системе. При росте количества записей в таблицах базыпользователи начали жаловаться на ошибки вида:```pythonInterfaceError: (InterfaceError) 2013: Lost connection to MySQL server during query u'SELECT..... '```Как вы думаете, почему это начало происходить и как локализовать проблему?Какие пути решения этой проблемы вы можете предложить?*Ответ*- Как вы думаете, почему это начало происходить и как локализовать проблему?\Количесво записей выросло, следовательно, какая-нибудь, тяжелая выборка (SELECT) будет обрабатываться дольше.Испытывая дифицит знаний в области dba и тем более troobleshuting`а данных сервисов обратился к документации и нашел вот что: [Error Messages and Common Problems](https://dev.mysql.com/doc/refman/8.0/en/error-lost-connection.html)-Какие пути решения этой проблемы вы можете предложить?  - Мы видим, что проблема у нас возникла в результате запроса. В указанной документации рекомендуют увеличить параметр `net_read_timeout` с `30` до `60` или больше  - Если это происходит при первоночальном подключении к базе меняем параметр `connect_timeout`  - Если проблема в передаче BLOB меняем `max_allowed_packet`## Задача 4Вы решили перевести гис-систему из задачи 3 на PostgreSQL, так как прочитали в документации, что эта СУБД работает с большим объёмом данных лучше, чем MySQL.После запуска пользователи начали жаловаться, что СУБД время от времени становится недоступной. В dmesg вы видите, что:`postmaster invoked oom-killer`Как вы думаете, что происходит?Как бы вы решили эту проблему?*Ответ*- Как вы думаете, что происходит?\   PGSQL хочет больше ОЗУ- Как бы вы решили эту проблему?  - Для начала ограничим PGSQL по памяти    - shared_buffers - 0,25 от весей памяти    - work_mem - 2-4% от доступной памяти, но не забываем о max_connection, ведь для каждого подключения свой work_mem. Так что корректируем с осторожностью.Y---### Как cдавать заданиеВыполненное домашнее задание пришлите ссылкой на .md-файл в вашем репозитории.---